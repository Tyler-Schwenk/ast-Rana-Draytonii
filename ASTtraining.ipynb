{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNI/D0/0GZZaJra5FEOvoLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyler-Schwenk/ast-Rana-Draytonii/blob/master/ASTtraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**clone the repo**"
      ],
      "metadata": {
        "id": "M3vtsdTCsXdZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEq6WnwksQg_",
        "outputId": "9adfe0da-c2c4-4d98-a9e5-79df9a8be7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ast-Rana-Draytonii'...\n",
            "remote: Enumerating objects: 718, done.\u001b[K\n",
            "remote: Counting objects: 100% (215/215), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 718 (delta 112), reused 189 (delta 98), pack-reused 503\u001b[K\n",
            "Receiving objects: 100% (718/718), 2.44 MiB | 25.54 MiB/s, done.\n",
            "Resolving deltas: 100% (372/372), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Tyler-Schwenk/ast-Rana-Draytonii.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount google drive where data is stored**\n",
        " (requires authentication)"
      ],
      "metadata": {
        "id": "ExwQbEZ3FztL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKnlnQG-Fs5r",
        "outputId": "9a64d40d-218d-4abd-bff1-8596aef5eb5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install dependencies**"
      ],
      "metadata": {
        "id": "_EH0XKViHyh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the 'ast' directory to sys.path\n",
        "import sys\n",
        "sys.path.append('./ast')\n",
        "\n",
        "# Install required packages\n",
        "!pip install timm==0.4.5\n",
        "!pip install wget\n",
        "!pip install torchaudio\n",
        "\n",
        "\n",
        "# Import necessary packages\n",
        "import os, csv, argparse, wget\n",
        "import torch, torchaudio, timm\n",
        "import numpy as np\n",
        "from torch.cuda.amp import autocast\n",
        "import IPython\n",
        "\n",
        "# Make sure you're in the right directory\n",
        "%cd ast/\n",
        "\n",
        "# Set the TORCH_HOME environment variable (for saving pretrained models)\n",
        "os.environ['TORCH_HOME'] = './pretrained_models'\n",
        "if os.path.exists('./pretrained_models') == False:\n",
        "  os.mkdir('./pretrained_models')"
      ],
      "metadata": {
        "id": "VIarrebOH0Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Navigate to correct directory**"
      ],
      "metadata": {
        "id": "O-PTQ3lS3u3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ast-Rana-Draytonii/egs/Rana7/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeL2VV1XHnzW",
        "outputId": "9da96358-ec4e-4ac1-be7e-140452b35ded"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ast-Rana-Draytonii/egs/Rana7/ast-Rana-Draytonii/egs/Rana7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#give execute permission to run.sh\n",
        "!chmod +x ./run.sh\n"
      ],
      "metadata": {
        "id": "NHf8ubz_JtTV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Update paths to be absolute**"
      ],
      "metadata": {
        "id": "qUwTuDcf1OZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Load the json file\n",
        "with open('/content/drive/MyDrive/Rana_Draytonii/Rana7/test_data.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Get the list of entries\n",
        "entries = data['data']\n",
        "\n",
        "# Iterate over the entries and update the paths\n",
        "for entry in entries:\n",
        "    entry['wav'] = os.path.join(base_dir, entry['wav'])\n",
        "\n",
        "# Update the 'data' key in the original dictionary\n",
        "data['data'] = entries\n",
        "\n",
        "# Write the data back out\n",
        "with open('/content/drive/MyDrive/Rana_Draytonii/Rana7/test_data.json', 'w') as f:\n",
        "    json.dump(data, f, indent=4)\n",
        "\n"
      ],
      "metadata": {
        "id": "l_yMuR3k1NVf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the training script**"
      ],
      "metadata": {
        "id": "l4tZb0NfHlC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./run.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98DEv8BmJhBB",
        "outputId": "90c2a365-3e24-458c-f53b-8b1da12ec17d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ export TORCH_HOME=../../pretrained_models\n",
            "+ TORCH_HOME=../../pretrained_models\n",
            "+ model=ast\n",
            "+ dataset=Rana_Draytonii\n",
            "+ set=balanced\n",
            "+ imagenetpretrain=False\n",
            "+ lr=1e-5\n",
            "+ epoch=5\n",
            "+ tr_data=/content/drive/MyDrive/Rana_Draytonii/Rana7/train_data.json\n",
            "+ te_data=/content/drive/MyDrive/Rana_Draytonii/Rana7/val_data.json\n",
            "+ freqm=48\n",
            "+ timem=200\n",
            "+ mixup=0.5\n",
            "+ fstride=10\n",
            "+ tstride=10\n",
            "+ batch_size=4\n",
            "+ dataset_mean=-4.27\n",
            "+ dataset_std=4.57\n",
            "+ audio_length=1000\n",
            "+ noise=False\n",
            "+ metrics=acc\n",
            "+ loss=BCE\n",
            "+ warmup=True\n",
            "+ wa=True\n",
            "+ exp_dir=./exp/test-balanced-f10-t10-pFalse-b4-lr1e-5-decoupe\n",
            "+ '[' -d ./exp/test-balanced-f10-t10-pFalse-b4-lr1e-5-decoupe ']'\n",
            "+ mkdir -p ./exp/test-balanced-f10-t10-pFalse-b4-lr1e-5-decoupe\n",
            "+ python -W ignore ../../src/run.py --model ast --dataset Rana_Draytonii --data-train /content/drive/MyDrive/Rana_Draytonii/Rana7/train_data.json --data-val /content/drive/MyDrive/Rana_Draytonii/Rana7/val_data.json --exp-dir ./exp/test-balanced-f10-t10-pFalse-b4-lr1e-5-decoupe --label-csv /content/drive/MyDrive/Rana_Draytonii/Rana7/labels.csv --n_class 2 --lr 1e-5 --n-epochs 5 --batch-size 4 --save_model True --freqm 48 --timem 200 --mixup 0.5 --tstride 10 --fstride 10 --imagenet_pretrain False --dataset_mean -4.27 --dataset_std 4.57 --audio_length 1000 --noise False --metrics acc --loss BCE --warmup True --wa True\n",
            "I am process 5571, running on ed3b3869000b: starting (Thu Jun 15 16:45:46 2023)\n",
            "now train a audio spectrogram transformer model\n",
            "balanced sampler is not used\n",
            "---------------the train dataloader---------------\n",
            "now using following mask: 48 freq, 200 time\n",
            "now using mix-up with rate 0.500000\n",
            "now process Rana_Draytonii\n",
            "use dataset mean -4.270 and std 4.570 to normalize the input.\n",
            "{'/m/positive': '0', '/m/negative': '1'}\n",
            "number of classes is 2\n",
            "---------------the evaluation dataloader---------------\n",
            "now using following mask: 0 freq, 0 time\n",
            "now using mix-up with rate 0.000000\n",
            "now process Rana_Draytonii\n",
            "use dataset mean -4.270 and std 4.570 to normalize the input.\n",
            "{'/m/positive': '0', '/m/negative': '1'}\n",
            "number of classes is 2\n",
            "---------------AST Model Summary---------------\n",
            "ImageNet pretraining: False, AudioSet pretraining: False\n",
            "frequncey stride=10, time stride=10\n",
            "number of patches=1188\n",
            "\n",
            "Creating experiment directory: ./exp/test-balanced-f10-t10-pFalse-b4-lr1e-5-decoupe\n",
            "Now starting training for 5 epochs\n",
            "running on cuda\n",
            "Total parameter number is : 87.710 million\n",
            "Total trainable parameter number is : 87.710 million\n",
            "now training with Rana_Draytonii, main metrics: acc, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fef7b62d5a0>\n",
            "The learning rate scheduler starts at 2 epoch with decay rate of 0.500 every 1 epochs\n",
            "current #steps=0, #epochs=1\n",
            "start training...\n",
            "---------------\n",
            "2023-06-15 16:45:49.644781\n",
            "current #epochs=1, #steps=0\n",
            "warm-up learning rate is 0.000000\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ast-Rana-Draytonii/egs/Rana7/ast-Rana-Draytonii/egs/Rana7/../../src/run.py\", line 143, in <module>\n",
            "    train(audio_model, train_loader, val_loader, args)\n",
            "  File \"/content/ast-Rana-Draytonii/egs/Rana7/ast-Rana-Draytonii/src/traintest.py\", line 109, in train\n",
            "    for i, (audio_input, labels) in enumerate(train_loader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "RuntimeError: Caught RuntimeError in DataLoader worker process 7.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/ast-Rana-Draytonii/egs/Rana7/ast-Rana-Draytonii/src/dataloader.py\", line 153, in __getitem__\n",
            "    fbank, mix_lambda = self._wav2fbank(datum['wav'], mix_datum['wav'])\n",
            "  File \"/content/ast-Rana-Draytonii/egs/Rana7/ast-Rana-Draytonii/src/dataloader.py\", line 117, in _wav2fbank\n",
            "    temp_wav[0, 0:waveform2.shape[1]] = waveform2\n",
            "RuntimeError: expand(torch.FloatTensor{[2, 159913]}, size=[159913]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}